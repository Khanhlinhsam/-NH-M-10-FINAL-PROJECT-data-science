# -*- coding: utf-8 -*-
"""Charts.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18Ly0s4b1ShC9tSrXPIjFb414mG1e5VUC
"""

!pip install -q streamlit
!pip install -q pyngrok
!pip install -q ydata-profiling
!pip install -q sweetviz

import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib
import matplotlib.pyplot as plt
import numpy as np
import sklearn
import statsmodels.api as sm
import sweetviz as sv
import http.server
import socketserver
from pyngrok import ngrok
import threading
import warnings
warnings.filterwarnings('ignore')
import statsmodels.api as sm
import squarify


from sklearn.linear_model import LassoCV
from sklearn import neighbors
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, RidgeCV, Lasso, LassoCV
from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error, roc_curve, auc
from sklearn.metrics import classification_report, mean_squared_error, r2_score
from sklearn.model_selection import cross_val_score, train_test_split
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, PolynomialFeatures, StandardScaler
from ydata_profiling import ProfileReport


from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.stats.stattools import durbin_watson
from statsmodels.tools.tools import add_constant

link = "https://drive.google.com/uc?id=1jtzs5MlKEm3tmm1axj_7RQqP3jjzI1XW"
data = pd.read_csv(link)

pd.set_option('display.max_columns', 500)

data.head(40)

grouped_data = data.groupby('hsc_s').agg(
    Total_Placed=('status', lambda x: (x == 'Placed').sum()),
    Average_Salary=('salary', 'mean')
).reset_index()

grouped_data['Average_Salary'] = grouped_data['Average_Salary'].fillna(0).round(2)
print(grouped_data)

fig, ax1 = plt.subplots(figsize=(10, 6))

ax1.bar(grouped_data['hsc_s'], grouped_data['Total_Placed'], color='skyblue', label='Total Placed')
ax1.set_xlabel('High School Specialisation (hsc_s)', fontsize=12)
ax1.set_ylabel('Total Placed', fontsize=12, color='black')
ax1.tick_params(axis='y', labelcolor='black')
ax1.set_title('Total Placed and Average Salary by High School Specialisation', fontsize=14)

ax2 = ax1.twinx()
ax2.plot(grouped_data['hsc_s'], grouped_data['Average_Salary'], color='red', marker='o', label='Average Salary')
ax2.set_ylabel('Average Salary (USD)', fontsize=12, color='black')
ax2.tick_params(axis='y', labelcolor='black')

fig.legend(loc='upper right', bbox_to_anchor=(1, 0.9), bbox_transform=ax1.transAxes)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

average_salary_by_gender_degree = data.groupby(['degree_t', 'gender'])['salary'].mean().reset_index()
average_salary_by_gender_degree.columns = ['Degree Type', 'Gender', 'Average Salary']

plt.figure(figsize=(8, 5))
sns.barplot(data=average_salary_by_gender_degree, x='Degree Type', y='Average Salary', hue='Gender', palette='Set2')
plt.title('Average salary of employees received by gender')
plt.ylabel('Salary')
plt.xlabel('Degree Type')
plt.legend(title='Gender')
plt.show()

average_scores = data.groupby('status')[['ssc_p', 'hsc_p', 'degree_p']].mean()

bar_height = 0.3
y_positions = np.arange(len(average_scores))
plt.barh(y_positions - bar_height, average_scores['ssc_p'], height=bar_height, label='ssc_p')
plt.barh(y_positions, average_scores['hsc_p'], height=bar_height, label='hsc_p')
plt.barh(y_positions + bar_height, average_scores['degree_p'], height=bar_height, label='degree_p')

plt.title('Average Score and Employment Status Bar Chart')
plt.xlabel('Average Score')
plt.yticks(y_positions, ['Not Placed', 'Placed'])
plt.legend(loc='lower right')
plt.tight_layout()
plt.show()

etest_greater_80 = data['etest_p'] > 80
etest_less_equal_80 = data['etest_p'] <= 80
workex_yes = data['workex'] == 'Yes'
workex_no = data['workex'] == 'No'
placed_status = data['status'] == 'Placed'
not_placed_status = data['status'] == 'Not Placed'

first_table = pd.DataFrame({
    'etest': ['>80', '>80', '<=80', '<=80'],
    'workex': ['Yes', 'No', 'Yes', 'No'],
    'Placed': [
        sumproduct_logic(etest_greater_80, workex_yes, placed_status),
        sumproduct_logic(etest_greater_80, workex_no, placed_status),
        sumproduct_logic(etest_less_equal_80, workex_yes, placed_status),
        sumproduct_logic(etest_less_equal_80, workex_no, placed_status)
    ],
    'Not Placed': [
        sumproduct_logic(etest_greater_80, workex_yes, not_placed_status),
        sumproduct_logic(etest_greater_80, workex_no, not_placed_status),
        sumproduct_logic(etest_less_equal_80, workex_yes, not_placed_status),
        sumproduct_logic(etest_less_equal_80, workex_no, not_placed_status)
    ]
})

first_table['Total'] = first_table['Placed'] + first_table['Not Placed']

second_table = first_table.copy()
second_table['Placed%'] = (second_table['Placed'] / second_table['Total'] * 100).fillna(0).round(1)
second_table['Not Placed%'] = (second_table['Not Placed'] / second_table['Total'] * 100).fillna(0).round(1)
second_table['Placed%'] = second_table['Placed%'].astype(str) + '%'
second_table['Not Placed%'] = second_table['Not Placed%'].astype(str) + '%'
second_table = second_table[['etest', 'workex', 'Placed%', 'Not Placed%']]

print("First Table:")
print(first_table[['etest', 'workex', 'Placed', 'Not Placed']])
print("\nSecond Table:")
print(second_table)

labels = [
    f"{row['etest']}, {row['workex']}\nPlaced: {row['Placed']}\nNot Placed: {row['Not Placed']}"
    for _, row in first_table.iterrows()
]
sizes = first_table['Total']

# Create treemap
plt.figure(figsize=(12, 8))
squarify.plot(sizes=sizes, label=labels, alpha=0.8)
plt.axis('off')
plt.title('Employment Rate by Work Experience and eTest Points', fontsize=16)
plt.show()

